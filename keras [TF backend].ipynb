{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Convolution1D, MaxPooling1D, Flatten, Dense, Dropout, merge, concatenate\n",
    "#from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utilities import my_callbacks\n",
    "from utilities import data_helper\n",
    "import optparse\n",
    "import sys\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data_helper.load_all(filelist=\"final_data/wsj.all\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading entity-gird for pos and neg documents...\")\n",
    "\n",
    "X_train_1, X_train_0, E = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.train\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, vocab_list=vocab, emb_size=100)\n",
    "\n",
    "X_dev_1, X_dev_0, E    = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.dev\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, E = E, vocab_list=vocab, emb_size=100)\n",
    "\n",
    "X_test_1, X_test_0, E    = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.test\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, E = E, vocab_list=vocab, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(X_train_1)\n",
    "num_dev   = len(X_dev_1)\n",
    "num_test  = len(X_test_1)\n",
    "#assign Y value\n",
    "y_train_1 = [1] * num_train \n",
    "y_dev_1 = [1] * num_dev \n",
    "y_test_1 = [1] * num_test \n",
    "\n",
    "print('.....................................')\n",
    "print(\"Num of traing pairs: \" + str(num_train))\n",
    "print(\"Num of dev pairs: \" + str(num_dev))\n",
    "print(\"Num of test pairs: \" + str(num_test))\n",
    "#print(\"Num of permutation in train: \" + str(opts.p_num)) \n",
    "#print(\"The maximum in length for CNN: \" + str(opts.maxlen))\n",
    "print('.....................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the outputs\n",
    "y_train_1 = np_utils.to_categorical(y_train_1, 2)\n",
    "y_dev_1 = np_utils.to_categorical(y_dev_1, 2)\n",
    "y_test_1 = np_utils.to_categorical(y_test_1, 2)\n",
    "\n",
    "#randomly shuffle the training data\n",
    "np.random.seed(113)\n",
    "np.random.shuffle(X_train_1)\n",
    "np.random.seed(113)\n",
    "np.random.shuffle(X_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "np.random.seed(113)\n",
    "\n",
    "E = 0.01 * np.random.uniform( -1.0, 1.0, (len(vocab), 100))\n",
    "E[len(vocab)-1] = 0\n",
    "#E\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranking_loss(y_true, y_pred):\n",
    "    pos = y_pred[:, 0]\n",
    "    neg = y_pred[:, 1]\n",
    "    #loss = -K.sigmoid(pos-neg) # use \n",
    "    loss = K.maximum(1.0 + neg - pos, 0.0) #if you want to use margin ranking loss\n",
    "    return K.mean(loss) + 0 * y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, define a CNN model for sequence of entities \n",
    "sent_input = Input(shape=(2000,), dtype='int32', name='sent_input')\n",
    "\n",
    "# embedding layer encodes the input into sequences of 300-dimenstional vectors. \n",
    "\n",
    "E = np.float32(E) #E was float64 which doesn't work for tensorflow conv1d function\n",
    "x = Embedding(input_dim=len(vocab), output_dim=100, weights= [E], input_length=2000)(sent_input)\n",
    "\n",
    "\n",
    "# add a convolutiaon 1D layer\n",
    "#x = Dropout(dropout_ratio)(x)\n",
    "filter_init =  tf.keras.initializers.glorot_uniform(seed=2018) \n",
    "x = Convolution1D(filters=150, kernel_size=6, padding='valid', activation='relu', kernel_initializer=filter_init)(x)\n",
    "\n",
    "\n",
    "# add max pooling layers\n",
    "#x = AveragePooling1D(pool_length=pool_length)(x)\n",
    "x = MaxPooling1D(pool_size=6)(x)\n",
    "\n",
    "\n",
    "#x = Dropout(opts.dropout_ratio)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "#x = Dense(hidden_size, activation='relu')(x)\n",
    "x = Dropout(0.5, seed=2018)(x)\n",
    "\n",
    "\n",
    "# add latent coherence score\n",
    "v_init = tf.keras.initializers.glorot_uniform(seed=2018) \n",
    "out_x = Dense(1, activation=None, kernel_initializer=v_init)(x)\n",
    "\n",
    "\n",
    "shared_cnn = Model(sent_input, out_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shared_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs of pos and neg document\n",
    "pos_input = Input(shape=(2000,), dtype='int32', name=\"pos_input\")\n",
    "neg_input = Input(shape=(2000,), dtype='int32', name=\"neg_input\")\n",
    "\n",
    "\n",
    "# these two models will share eveything from shared_cnn\n",
    "pos_branch = shared_cnn(pos_input)\n",
    "neg_branch = shared_cnn(neg_input)\n",
    "\n",
    "\n",
    "\n",
    "concatenated = merge([pos_branch, neg_branch], mode='concat', name=\"coherence_out\")\n",
    "#concatenated = concatenate([pos_branch, neg_branch], name=\"coherence_out\")\n",
    "# output is two latent coherence score\n",
    "\n",
    "\n",
    "final_model = Model([pos_input, neg_input], concatenated)\n",
    "\n",
    "\n",
    "#final_model.compile(loss='ranking_loss', optimizer='adam')\n",
    "final_model.compile(loss={'coherence_out': ranking_loss}, optimizer=\"rmsprop\")\n",
    "\n",
    "# setting callback\n",
    "histories = my_callbacks.Histories()\n",
    "\n",
    "#print(shared_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit([X_train_1, X_train_0], y_train_1, validation_data=None, shuffle=False, epochs=1,\n",
    "                                  verbose=0, batch_size=32, callbacks=[histories])\n",
    "\n",
    "#print(history.history.keys())\n",
    "#print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, loss) in enumerate(histories.losses):\n",
    "    print(\"Iteration \",i, \":  \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = final_model.predict([X_test_1, X_test_0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ties = 0\n",
    "wins = 0\n",
    "n = len(y_pred)\n",
    "for i in range(0,n):\n",
    "    if y_pred[i][0] > y_pred[i][1]:\n",
    "        wins = wins + 1\n",
    "    elif y_pred[i][0] == y_pred[i][1]:\n",
    "        ties = ties + 1\n",
    "#print(\"Perform on test set after Epoch: \" + str(ep) + \"...!\")    \n",
    "print(\" -Wins: \" + str(wins) + \" Ties: \"  + str(ties))\n",
    "loss = n - (wins+ties)\n",
    "\n",
    "recall = wins/n;\n",
    "prec = wins/(wins + loss)\n",
    "f1 = 2*prec*recall/(prec+recall)\n",
    "\n",
    "print(\" -Test acc: \" + str(wins/n))\n",
    "print(\" -Test f1 : \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
