{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Convolution1D, MaxPooling1D, Flatten, Dense, Dropout, merge, concatenate\n",
    "#from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utilities import my_callbacks\n",
    "from utilities import data_helper\n",
    "import optparse\n",
    "import sys\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: None\n",
      "{'-': 2449404, 'X': 162058, 'S': 52415, 'O': 30440}\n",
      "Total vocabulary size in the whole dataset: 4\n",
      "['-', 'O', 'S', 'X', '0']\n"
     ]
    }
   ],
   "source": [
    "vocab = data_helper.load_all(filelist=\"final_data/wsj.all\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading entity-gird for pos and neg documents...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading entity-gird for pos and neg documents...\")\n",
    "\n",
    "X_train_1, X_train_0, E = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.train\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, vocab_list=vocab, emb_size=100)\n",
    "\n",
    "X_dev_1, X_dev_0, E    = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.dev\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, E = E, vocab_list=vocab, emb_size=100)\n",
    "\n",
    "X_test_1, X_test_0, E    = data_helper.load_and_numberize_Egrid_with_Feats(\"final_data/wsj.test\", \n",
    "        perm_num = 20, maxlen=2000, window_size=6, E = E, vocab_list=vocab, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................\n",
      "Num of traing pairs: 23744\n",
      "Num of dev pairs: 2678\n",
      "Num of test pairs: 20411\n",
      ".....................................\n"
     ]
    }
   ],
   "source": [
    "num_train = len(X_train_1)\n",
    "num_dev   = len(X_dev_1)\n",
    "num_test  = len(X_test_1)\n",
    "#assign Y value\n",
    "y_train_1 = [1] * num_train \n",
    "y_dev_1 = [1] * num_dev \n",
    "y_test_1 = [1] * num_test \n",
    "\n",
    "print('.....................................')\n",
    "print(\"Num of traing pairs: \" + str(num_train))\n",
    "print(\"Num of dev pairs: \" + str(num_dev))\n",
    "print(\"Num of test pairs: \" + str(num_test))\n",
    "#print(\"Num of permutation in train: \" + str(opts.p_num)) \n",
    "#print(\"The maximum in length for CNN: \" + str(opts.maxlen))\n",
    "print('.....................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the outputs\n",
    "y_train_1 = np_utils.to_categorical(y_train_1, 2)\n",
    "y_dev_1 = np_utils.to_categorical(y_dev_1, 2)\n",
    "y_test_1 = np_utils.to_categorical(y_test_1, 2)\n",
    "\n",
    "#randomly shuffle the training data\n",
    "np.random.seed(113)\n",
    "np.random.shuffle(X_train_1)\n",
    "np.random.seed(113)\n",
    "np.random.shuffle(X_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp.random.seed(113)\\n\\nE = 0.01 * np.random.uniform( -1.0, 1.0, (len(vocab), 100))\\nE[len(vocab)-1] = 0\\n#E\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "np.random.seed(113)\n",
    "\n",
    "E = 0.01 * np.random.uniform( -1.0, 1.0, (len(vocab), 100))\n",
    "E[len(vocab)-1] = 0\n",
    "#E\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranking_loss(y_true, y_pred):\n",
    "    pos = y_pred[:, 0]\n",
    "    neg = y_pred[:, 1]\n",
    "    #loss = -K.sigmoid(pos-neg) # use \n",
    "    loss = K.maximum(1.0 + neg - pos, 0.0) #if you want to use margin ranking loss\n",
    "    return K.mean(loss) + 0 * y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, define a CNN model for sequence of entities \n",
    "sent_input = Input(shape=(2000,), dtype='int32', name='sent_input')\n",
    "\n",
    "# embedding layer encodes the input into sequences of 300-dimenstional vectors. \n",
    "\n",
    "E = np.float32(E) #E was float64 which doesn't work for tensorflow conv1d function\n",
    "x = Embedding(input_dim=len(vocab), output_dim=100, weights= [E], input_length=2000)(sent_input)\n",
    "\n",
    "\n",
    "# add a convolutiaon 1D layer\n",
    "#x = Dropout(dropout_ratio)(x)\n",
    "filter_init =  tf.keras.initializers.glorot_uniform(seed=2018) \n",
    "x = Convolution1D(filters=150, kernel_size=6, padding='valid', activation='relu', kernel_initializer=filter_init)(x)\n",
    "\n",
    "\n",
    "# add max pooling layers\n",
    "#x = AveragePooling1D(pool_length=pool_length)(x)\n",
    "x = MaxPooling1D(pool_size=6)(x)\n",
    "\n",
    "\n",
    "#x = Dropout(opts.dropout_ratio)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "#x = Dense(hidden_size, activation='relu')(x)\n",
    "x = Dropout(0.5, seed=2018)(x)\n",
    "\n",
    "\n",
    "# add latent coherence score\n",
    "v_init = tf.keras.initializers.glorot_uniform(seed=2018) \n",
    "out_x = Dense(1, activation=None, kernel_initializer=v_init)(x)\n",
    "\n",
    "\n",
    "shared_cnn = Model(sent_input, out_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 2000, 100)         500       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1995, 150)         90150     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 332, 150)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 49800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 49800)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 49801     \n",
      "=================================================================\n",
      "Total params: 140,451\n",
      "Trainable params: 140,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(shared_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tasnim/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if sys.path[0] == '':\n",
      "/home/tasnim/tensorflow/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# Inputs of pos and neg document\n",
    "pos_input = Input(shape=(2000,), dtype='int32', name=\"pos_input\")\n",
    "neg_input = Input(shape=(2000,), dtype='int32', name=\"neg_input\")\n",
    "\n",
    "\n",
    "# these two models will share eveything from shared_cnn\n",
    "pos_branch = shared_cnn(pos_input)\n",
    "neg_branch = shared_cnn(neg_input)\n",
    "\n",
    "\n",
    "\n",
    "concatenated = merge([pos_branch, neg_branch], mode='concat', name=\"coherence_out\")\n",
    "#concatenated = concatenate([pos_branch, neg_branch], name=\"coherence_out\")\n",
    "# output is two latent coherence score\n",
    "\n",
    "\n",
    "final_model = Model([pos_input, neg_input], concatenated)\n",
    "\n",
    "\n",
    "#final_model.compile(loss='ranking_loss', optimizer='adam')\n",
    "final_model.compile(loss={'coherence_out': ranking_loss}, optimizer=\"rmsprop\")\n",
    "\n",
    "# setting callback\n",
    "histories = my_callbacks.Histories()\n",
    "\n",
    "#print(shared_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch:  0   ******************\n",
      "Wins:  16582\n",
      "Ties:  0\n",
      "losses:  3829\n",
      " -Test acc: 0.8124050756944785\n",
      " -Test f1 : 0.8124050756944785\n",
      "***********Epoch:  1   ******************\n",
      "Wins:  16487\n",
      "Ties:  0\n",
      "losses:  3924\n",
      " -Test acc: 0.8077507226495517\n",
      " -Test f1 : 0.8077507226495518\n",
      "***********Epoch:  2   ******************\n",
      "Wins:  16433\n",
      "Ties:  0\n",
      "losses:  3978\n",
      " -Test acc: 0.8051050903924355\n",
      " -Test f1 : 0.8051050903924355\n",
      "***********Epoch:  3   ******************\n",
      "Wins:  16350\n",
      "Ties:  0\n",
      "losses:  4061\n",
      " -Test acc: 0.8010386556268678\n",
      " -Test f1 : 0.8010386556268678\n",
      "***********Epoch:  4   ******************\n",
      "Wins:  16366\n",
      "Ties:  0\n",
      "losses:  4045\n",
      " -Test acc: 0.8018225466660134\n",
      " -Test f1 : 0.8018225466660133\n",
      "***********Epoch:  5   ******************\n",
      "Wins:  16397\n",
      "Ties:  0\n",
      "losses:  4014\n",
      " -Test acc: 0.8033413355543579\n",
      " -Test f1 : 0.8033413355543579\n",
      "***********Epoch:  6   ******************\n",
      "Wins:  16286\n",
      "Ties:  0\n",
      "losses:  4125\n",
      " -Test acc: 0.7979030914702856\n",
      " -Test f1 : 0.7979030914702856\n",
      "***********Epoch:  7   ******************\n",
      "Wins:  16462\n",
      "Ties:  0\n",
      "losses:  3949\n",
      " -Test acc: 0.8065258929008868\n",
      " -Test f1 : 0.8065258929008867\n",
      "***********Epoch:  8   ******************\n",
      "Wins:  16465\n",
      "Ties:  0\n",
      "losses:  3946\n",
      " -Test acc: 0.8066728724707266\n",
      " -Test f1 : 0.8066728724707266\n",
      "***********Epoch:  9   ******************\n",
      "Wins:  16421\n",
      "Ties:  0\n",
      "losses:  3990\n",
      " -Test acc: 0.8045171721130763\n",
      " -Test f1 : 0.8045171721130763\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    \n",
    "    #Train Phase:\n",
    "    \n",
    "    final_model.fit([X_train_1, X_train_0], y_train_1, validation_data=None, shuffle=False, epochs=1,\n",
    "                                  verbose=0, batch_size=32, callbacks=[histories])\n",
    "    \n",
    "    #Test Phase:\n",
    "    \n",
    "    y_pred = final_model.predict([X_test_1, X_test_0])        \n",
    "    \n",
    "    ties = 0\n",
    "    wins = 0\n",
    "    n = len(y_pred)\n",
    "    for i in range(0,n):\n",
    "        if y_pred[i][0] > y_pred[i][1]:\n",
    "            wins = wins + 1\n",
    "        elif y_pred[i][0] == y_pred[i][1]:\n",
    "            ties = ties + 1\n",
    "    #print(\"Perform on test set after Epoch: \" + str(ep) + \"...!\")    \n",
    "    #print(\" -Wins: \" + str(wins) + \" Ties: \"  + str(ties))\n",
    "    loss = n - (wins+ties)\n",
    "\n",
    "    recall = wins/n;\n",
    "    prec = wins/(wins + loss)\n",
    "    f1 = 2*prec*recall/(prec+recall)\n",
    "    \n",
    "    \n",
    "    print(\"***********Epoch: \",ep,\"  ******************\")\n",
    "    \n",
    "    print(\"Wins: \", wins)\n",
    "    print(\"Ties: \", ties)\n",
    "    print(\"losses: \", loss)\n",
    "\n",
    "    print(\" -Test acc: \" + str(wins/n))\n",
    "    print(\" -Test f1 : \" + str(f1))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for (i, loss) in enumerate(histories.losses):\n",
    "    #print(\"Iteration \",i, \":  \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
